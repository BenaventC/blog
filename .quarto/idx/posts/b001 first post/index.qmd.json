{"title":"Note n°1 : Les réseaux sociaux polarisent-ils?","markdown":{"yaml":{"title":"Note n°1 : Les réseaux sociaux polarisent-ils?","author":"Christophe Benavent","date":"2023-08-06","categories":["Social Media","Polarisation","Algorithme","Bubble filter","Politique","Notes","Sociologie"]},"containsRefs":false,"markdown":"\n\nLe débat public se nourrit souvent plus d'hypothèses que de faits, il emploie la théorie moins pour comprendre le monde que pour lui appliquer un cadre d'analyse auquel on adhère sans critique, au risque d'en faire un cadre idéologique. La théorie l'effet de polarisation des réseaux sociaux est un bon exemple, nourrissant la défiance qu'on leur témoigne, en attribuant leurs effets aux dispositifs algorithmique, et justifiant ainsi la nécessité de les réguler. Or cette thèse trouve un soutien modeste dans les études empiriques.\n\n![from Pew research https://www.pewresearch.org/politics/2014/06/12/political-polarization-in-the-american-public/pp-2014-06-12-polarization-0-05/](polarisation_pew.jpg)\n\nPopularisée par @pariser_filter_2012, la thèse des bulles de filtre, et celle des chambres d'écho, suggère que les opinions tendent à se polariser et se se radicaliser quand elles se forment dans le bain des réseaux sociaux que les algorithmes font bouillonner.\n\nC'est une hypothèse qui trouve sa raison dans le concept de l'attachement préférentiel @barabasi_scale-free_2009, qui génère une topologie caractéristique des réseaux : la distribution puissance du nombre de liens : une minorité est liée à un grand nombre de nœud, une très grande majorité est peu liée aux autres. Ce mécanisme fondamental génère une exposition sélective : chaque nouveau nœud, dans le réseau se nouant aux nœuds les plus populaires.\n\nDe manière plus sociologique, l'attachement préférentiel joue de manière un peu différente. Il est d'abord gouverné par le fait qu'on tend à s'exposer à des gens qui nous ressemblent. C'est une hypothèse raisonnable car elle se fonde sur un mécanisme d'homophilie que les chercheurs ont mis à jour depuis longtemps, distinguant d'ailleurs celle induite par la proximité dans le réseau (les amis de nos amis) de celle générée par similarités d'intérêt (@kossinets_origins_2009).\n\nSur un plan psychologique, un second mécanisme peut être ajouté, celui de l'attention sélective (@janiszewski_influence_2013) surtout si elle se conjugue à des biais de confirmation (@nickerson_confirmation_1998).\n\nLe troisième mécanisme est technologique, c'est un mécanisme de renforcement qui se joue dans les systèmes de recommandation de nouveaux contacts et de contenus, les algorithmes amplifieraient l'exposition des sujets à ceux avec lesquels ils partagent les mêmes idées. Ce sont les chambres d'écho.\n\nQuand l'ensemble de ces mécanismes s'associent, chacun se trouverait ainsi plus ou moins rapidement isolé dans une bulle dont la surface est le prisme de nos préférences. Un article de @geschke_triple-filter_2019 en donne une bonne idée en distinguant justement ces trois type de filtres : individuels (notamment les biais de confirmation mais aussi de recherche de diversité), sociaux (homophilie), et technologiques (moteurs de recommandation). En examinant leurs interactions par des modèles d'agents (ABM), ils montrent que la polarisation émerge quand il y a interaction entre la diffusion centrale de l'information (mass media), partage social de cette information et activation de systèmes de recommandation. Ces derniers pouvant modérer la polarisation lorsque ce qui est recommandé va dans le sens de la diversité de l'information.\n\nOuvrons une rapide parenthèse, les algorithmes de recommandation servent des buts variés. En général, l'objectif est d'incité l'utilisation à consulter le plus de page possible, pour être exposé aux plus de publicité, ou au plus d'occasion de consommer. Mais des designs différents peuvent être proposés pour résoudre d'autres problèmes, dans les plateformes de musique, l'ennui est un danger et très tôt on a pensé introduire des techniques de sérendipité, le moyen de produire des saut dans les cheminement thématique. Les algorithmes ne sont pas monolithiques, ni dans leur conception, si dans leurs objectifs.\n\nFermons la parenthèse et revenons à la question principale de l'attribution d'une responsabilité aux réseaux sociaux dans le phénomène de la polarisation politique, qui se manifeste tant par l'écart croissant entre les positions relatives des valeurs de droite et gauche, que par l'intensité du rejet des uns par les autres, en la justifiant par ces hypothétiques bulles de filtre qui en isolant les sujets d'opinions différentes, conduit à la radicalisation des opinions et à la surdité à l'égard des arguments de l'autre partie.\n\nPour que cette théorie le deviennent vraiment, et ainsi échappe à l'appropriation de l'idéologie, il est nécessaire que les faits ne la démentent pas. Depuis quelques années, des études à grandes échelle et pour une bonne part expérimentales, ont été menées et leurs résultats publiés. Ils sont extrêmement modestes sur l'effet de polarisation, tout en démontrant l'importance des effets d'exposition.\n\nSchématisons l'idée :\n\n```{mermaid}\nflowchart LR\nAlgorithmes--Renforcement--> B(Exposition Sélective)\nAlgorithmes --recommandation--> Homophilie\nAlgorithmes--nudge--> C(Attention Selective) \nHomophilie --imitation-->  C(Attention Selective) \nHomophilie --> B(Exposition Sélective)\nHomophilie --conformisme-->  D(Polarisation) \n B[Exposition Sélective]  -->  C(Attention Selective) \n C(Attention Selective)  -->  D(Polarisation) \n B[Exposition Sélective]  --chambre d'écho-->  D(Polarisation) \n\n```\n\nLa première étude empirique vient de facebook @kramer_experimental_2014, elle a été fermement critiquée dans la mesure où les sujets n'ont pas été informés violant clairement un principe déontologique évident. Il s'agissait de contrôler le fil de nouvelles d'une large population en réduisant indépendemment la proportion de messages positifs et négatifs, puis en observant les conséquences sur le caractère négatif ou positif de la production des sujets exposés. L'hypothèse a été validée mais avec un effet finalement très faible. Si il y a contagion, est est superficielle.\n\n@huszar_algorithmic_2022 ont conduit quant à eux, un audit de Twitter menant une sorte d'expérience naturelle en comparant un groupe de compte auquel le réseau n'a jamais appliqué ses algorithmes (depuis 2016) et un autre groupe, expérimental, qui subit la curation automatisée de contenu. En construisant un indicateur de multiplication, ils comparent dans 7 pays les effets sur les tweets produits par les hommes politiques et selon leur affiliation. Il apparaît que l'effet d'amplification joue, mieux à droite qu'à gauche comme attendu, mais plus pour les partis centraux que pour les extrêmes, ce qui était moins attendu . Dans le même esprit @gonzalez-bailon_asymmetric_2023 montre le même phénomène en analysant les contenus vu par 208 millions de compte facebook : c'est vers l'extrême droite que la proportion de pages et de groupes \"douteux\" est la plus grande, et que plus forte est la ségrégation de la consommation de news.\n\nTrès récemment @guess_how_2023 , et @nyhan_like-minded_2023 ont testé spécifiquement l'effet des algorithmes de recommandation en randomisant, au cours de la campagne présidentielle américaine de 2020, l'exposition soit aux algorithmes habituels, soit un simple fil ante-chronologique. Avec ce dernier les temps passés sur la plateformes se réduisent, ainsi que les like et commentaires (réduction de moitié) - ce qui au passage confirme l'efficacité des algorithmes pour accroître l'exposition à la publicité - alors que la diversité des contenus auxquels sont exposés les comptes s'accroît. En revanche, même après trois mois de traitement, le degré de polarisation et plus largement les attitudes ne semblent pas changer. L'exposition sélective n'est pas suffisante pour changer les opinions.\n\nCes résultats empiriques sont si modestes, qu'un nouvel argument émerge du débat. C'est celui des petits effets (@gotz_small_2022) qui s'accumulent, éventuellement se multiplient et finalement ne sont pas incompatibles avec ce qui est observé. C'est une conception qui a trouvé rapidement sa contradiction @primbs_are_2023.. A propos de notre question en voici un bon [exemple](https://tecunningham.github.io/posts/2023-07-27-meta-2020-elections-experiments.html).\n\nFinalement, les choses apparaissent plus plus complexes, à la fois par les hypothèses, mais aussi par les processus. L'attention sélective ne sélectionne pas toujours le même, elle peut favoriser le différent, ou simplement se concentrer sur les informations qu'ils faut écarter. L'homophilie n'est peut être pas si systématique, la réalité empirique des réseaux sociaux est qu'on jamais affaire, ou rarement à des composants isolés : la topologie générale est celle d'un macro-composant, chacun est lié à tous et à bien moins de 6 degré de liberté. Les systèmes de recommandation ne sont pas si efficaces que ça, et dans certain cas (musique) intègrent des composants de génération de diversité. Leur design n'est pas monolithique. Sans compter que la crédibilité de l'information qui vient des réseaux sociaux est bien plus faible que celle des autres médias, ce qu'on y cherche c'est l'étonnant, l'amusant, le sensationnel, bref le divertissement. Sans doute assez peu d'arguments pour juger le monde.\n\nPeut-être finalement faut-il recentrer la question. Si la vie politique se polarise, c'est sans doute moins par l'alchimie des réseaux sociaux, que par des rapports politiques beaucoup fondamentaux. La véritable question se pose en fait dans la transformation idéologique plus que dans la frénésie médiatique. Une transformation qui se dessine dans le rapport aux institutions, et à l' incapacité de leur maîtrise.\n\nL'expérience du Covid et de la vaccination en a sans doute été un révélateur. Pour part de la population qui s'est opposée radicalement à la vaccination, le trait discriminant était la défiance à l'égard des institutions, politiques, scientifiques et sanitaires. Il va de soi que si la confiance dans les institutions s'effondre, leur discours n'est plus audible et conduit ces acteurs à la recherche de vérités alternatives. La question de la polarisation reste donc d'abord une question politique. Voilà qui n'empêche pas de considérer comment les acteurs politiques, extrêmes ou non, emploient les technologies de l'information et de la communication.\n","srcMarkdownNoYaml":"\n\nLe débat public se nourrit souvent plus d'hypothèses que de faits, il emploie la théorie moins pour comprendre le monde que pour lui appliquer un cadre d'analyse auquel on adhère sans critique, au risque d'en faire un cadre idéologique. La théorie l'effet de polarisation des réseaux sociaux est un bon exemple, nourrissant la défiance qu'on leur témoigne, en attribuant leurs effets aux dispositifs algorithmique, et justifiant ainsi la nécessité de les réguler. Or cette thèse trouve un soutien modeste dans les études empiriques.\n\n![from Pew research https://www.pewresearch.org/politics/2014/06/12/political-polarization-in-the-american-public/pp-2014-06-12-polarization-0-05/](polarisation_pew.jpg)\n\nPopularisée par @pariser_filter_2012, la thèse des bulles de filtre, et celle des chambres d'écho, suggère que les opinions tendent à se polariser et se se radicaliser quand elles se forment dans le bain des réseaux sociaux que les algorithmes font bouillonner.\n\nC'est une hypothèse qui trouve sa raison dans le concept de l'attachement préférentiel @barabasi_scale-free_2009, qui génère une topologie caractéristique des réseaux : la distribution puissance du nombre de liens : une minorité est liée à un grand nombre de nœud, une très grande majorité est peu liée aux autres. Ce mécanisme fondamental génère une exposition sélective : chaque nouveau nœud, dans le réseau se nouant aux nœuds les plus populaires.\n\nDe manière plus sociologique, l'attachement préférentiel joue de manière un peu différente. Il est d'abord gouverné par le fait qu'on tend à s'exposer à des gens qui nous ressemblent. C'est une hypothèse raisonnable car elle se fonde sur un mécanisme d'homophilie que les chercheurs ont mis à jour depuis longtemps, distinguant d'ailleurs celle induite par la proximité dans le réseau (les amis de nos amis) de celle générée par similarités d'intérêt (@kossinets_origins_2009).\n\nSur un plan psychologique, un second mécanisme peut être ajouté, celui de l'attention sélective (@janiszewski_influence_2013) surtout si elle se conjugue à des biais de confirmation (@nickerson_confirmation_1998).\n\nLe troisième mécanisme est technologique, c'est un mécanisme de renforcement qui se joue dans les systèmes de recommandation de nouveaux contacts et de contenus, les algorithmes amplifieraient l'exposition des sujets à ceux avec lesquels ils partagent les mêmes idées. Ce sont les chambres d'écho.\n\nQuand l'ensemble de ces mécanismes s'associent, chacun se trouverait ainsi plus ou moins rapidement isolé dans une bulle dont la surface est le prisme de nos préférences. Un article de @geschke_triple-filter_2019 en donne une bonne idée en distinguant justement ces trois type de filtres : individuels (notamment les biais de confirmation mais aussi de recherche de diversité), sociaux (homophilie), et technologiques (moteurs de recommandation). En examinant leurs interactions par des modèles d'agents (ABM), ils montrent que la polarisation émerge quand il y a interaction entre la diffusion centrale de l'information (mass media), partage social de cette information et activation de systèmes de recommandation. Ces derniers pouvant modérer la polarisation lorsque ce qui est recommandé va dans le sens de la diversité de l'information.\n\nOuvrons une rapide parenthèse, les algorithmes de recommandation servent des buts variés. En général, l'objectif est d'incité l'utilisation à consulter le plus de page possible, pour être exposé aux plus de publicité, ou au plus d'occasion de consommer. Mais des designs différents peuvent être proposés pour résoudre d'autres problèmes, dans les plateformes de musique, l'ennui est un danger et très tôt on a pensé introduire des techniques de sérendipité, le moyen de produire des saut dans les cheminement thématique. Les algorithmes ne sont pas monolithiques, ni dans leur conception, si dans leurs objectifs.\n\nFermons la parenthèse et revenons à la question principale de l'attribution d'une responsabilité aux réseaux sociaux dans le phénomène de la polarisation politique, qui se manifeste tant par l'écart croissant entre les positions relatives des valeurs de droite et gauche, que par l'intensité du rejet des uns par les autres, en la justifiant par ces hypothétiques bulles de filtre qui en isolant les sujets d'opinions différentes, conduit à la radicalisation des opinions et à la surdité à l'égard des arguments de l'autre partie.\n\nPour que cette théorie le deviennent vraiment, et ainsi échappe à l'appropriation de l'idéologie, il est nécessaire que les faits ne la démentent pas. Depuis quelques années, des études à grandes échelle et pour une bonne part expérimentales, ont été menées et leurs résultats publiés. Ils sont extrêmement modestes sur l'effet de polarisation, tout en démontrant l'importance des effets d'exposition.\n\nSchématisons l'idée :\n\n```{mermaid}\nflowchart LR\nAlgorithmes--Renforcement--> B(Exposition Sélective)\nAlgorithmes --recommandation--> Homophilie\nAlgorithmes--nudge--> C(Attention Selective) \nHomophilie --imitation-->  C(Attention Selective) \nHomophilie --> B(Exposition Sélective)\nHomophilie --conformisme-->  D(Polarisation) \n B[Exposition Sélective]  -->  C(Attention Selective) \n C(Attention Selective)  -->  D(Polarisation) \n B[Exposition Sélective]  --chambre d'écho-->  D(Polarisation) \n\n```\n\nLa première étude empirique vient de facebook @kramer_experimental_2014, elle a été fermement critiquée dans la mesure où les sujets n'ont pas été informés violant clairement un principe déontologique évident. Il s'agissait de contrôler le fil de nouvelles d'une large population en réduisant indépendemment la proportion de messages positifs et négatifs, puis en observant les conséquences sur le caractère négatif ou positif de la production des sujets exposés. L'hypothèse a été validée mais avec un effet finalement très faible. Si il y a contagion, est est superficielle.\n\n@huszar_algorithmic_2022 ont conduit quant à eux, un audit de Twitter menant une sorte d'expérience naturelle en comparant un groupe de compte auquel le réseau n'a jamais appliqué ses algorithmes (depuis 2016) et un autre groupe, expérimental, qui subit la curation automatisée de contenu. En construisant un indicateur de multiplication, ils comparent dans 7 pays les effets sur les tweets produits par les hommes politiques et selon leur affiliation. Il apparaît que l'effet d'amplification joue, mieux à droite qu'à gauche comme attendu, mais plus pour les partis centraux que pour les extrêmes, ce qui était moins attendu . Dans le même esprit @gonzalez-bailon_asymmetric_2023 montre le même phénomène en analysant les contenus vu par 208 millions de compte facebook : c'est vers l'extrême droite que la proportion de pages et de groupes \"douteux\" est la plus grande, et que plus forte est la ségrégation de la consommation de news.\n\nTrès récemment @guess_how_2023 , et @nyhan_like-minded_2023 ont testé spécifiquement l'effet des algorithmes de recommandation en randomisant, au cours de la campagne présidentielle américaine de 2020, l'exposition soit aux algorithmes habituels, soit un simple fil ante-chronologique. Avec ce dernier les temps passés sur la plateformes se réduisent, ainsi que les like et commentaires (réduction de moitié) - ce qui au passage confirme l'efficacité des algorithmes pour accroître l'exposition à la publicité - alors que la diversité des contenus auxquels sont exposés les comptes s'accroît. En revanche, même après trois mois de traitement, le degré de polarisation et plus largement les attitudes ne semblent pas changer. L'exposition sélective n'est pas suffisante pour changer les opinions.\n\nCes résultats empiriques sont si modestes, qu'un nouvel argument émerge du débat. C'est celui des petits effets (@gotz_small_2022) qui s'accumulent, éventuellement se multiplient et finalement ne sont pas incompatibles avec ce qui est observé. C'est une conception qui a trouvé rapidement sa contradiction @primbs_are_2023.. A propos de notre question en voici un bon [exemple](https://tecunningham.github.io/posts/2023-07-27-meta-2020-elections-experiments.html).\n\nFinalement, les choses apparaissent plus plus complexes, à la fois par les hypothèses, mais aussi par les processus. L'attention sélective ne sélectionne pas toujours le même, elle peut favoriser le différent, ou simplement se concentrer sur les informations qu'ils faut écarter. L'homophilie n'est peut être pas si systématique, la réalité empirique des réseaux sociaux est qu'on jamais affaire, ou rarement à des composants isolés : la topologie générale est celle d'un macro-composant, chacun est lié à tous et à bien moins de 6 degré de liberté. Les systèmes de recommandation ne sont pas si efficaces que ça, et dans certain cas (musique) intègrent des composants de génération de diversité. Leur design n'est pas monolithique. Sans compter que la crédibilité de l'information qui vient des réseaux sociaux est bien plus faible que celle des autres médias, ce qu'on y cherche c'est l'étonnant, l'amusant, le sensationnel, bref le divertissement. Sans doute assez peu d'arguments pour juger le monde.\n\nPeut-être finalement faut-il recentrer la question. Si la vie politique se polarise, c'est sans doute moins par l'alchimie des réseaux sociaux, que par des rapports politiques beaucoup fondamentaux. La véritable question se pose en fait dans la transformation idéologique plus que dans la frénésie médiatique. Une transformation qui se dessine dans le rapport aux institutions, et à l' incapacité de leur maîtrise.\n\nL'expérience du Covid et de la vaccination en a sans doute été un révélateur. Pour part de la population qui s'est opposée radicalement à la vaccination, le trait discriminant était la défiance à l'égard des institutions, politiques, scientifiques et sanitaires. Il va de soi que si la confiance dans les institutions s'effondre, leur discours n'est plus audible et conduit ces acteurs à la recherche de vérités alternatives. La question de la polarisation reste donc d'abord une question politique. Voilà qui n'empêche pas de considérer comment les acteurs politiques, extrêmes ou non, emploient les technologies de l'information et de la communication.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.353","editor":"visual","bibliography":["../../blog.bib"],"theme":"cosmo","title-block-banner":true,"title":"Note n°1 : Les réseaux sociaux polarisent-ils?","author":"Christophe Benavent","date":"2023-08-06","categories":["Social Media","Polarisation","Algorithme","Bubble filter","Politique","Notes","Sociologie"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}