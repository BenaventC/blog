---
title: "Note n°1 : Les réseaux sociaux polarisent-ils?"
author: "Christophe Benavent"
date: "2023-08-06"
categories: [Social Media,Polarisation, Algorithme, Bubble filter, Politique, Notes, Sociologie]
---

Le débat public se nourrit souvent plus d'hypothèses que de faits, il emploie la théorie moins pour comprendre le monde que pour lui appliquer un cadre d'analyse auquel on adhère sans critique, au risque d'en faire un cadre idéologique. La théorie l'effet de polarisation des réseaux sociaux est un bon exemple, nourrissant la défiance qu'on leur témoigne, en attribuant leurs effets aux dispositifs algorithmique, et justifiant ainsi la nécessité de les réguler. Or cette thèse trouve un soutien modeste dans les études empiriques.

![from Pew research https://www.pewresearch.org/politics/2014/06/12/political-polarization-in-the-american-public/pp-2014-06-12-polarization-0-05/](polarisation_pew.jpg)

Popularisée par @pariser_filter_2012, la thèse des bulles de filtre, et celle des chambres d'écho, suggère que les opinions tendent à se polariser et se se radicaliser quand elles se forment dans le bain des réseaux sociaux que les algorithmes font bouillonner.

C'est une hypothèse qui trouve sa raison dans le concept de l'attachement préférentiel @barabasi_scale-free_2009, qui génère une topologie caractéristique des réseaux : la distribution puissance du nombre de liens : une minorité est liée à un grand nombre de nœud, une très grande majorité est peu liée aux autres. Ce mécanisme fondamental génère une exposition sélective : chaque nouveau nœud, dans le réseau se nouant aux nœuds les plus populaires.

De manière plus sociologique, l'attachement préférentiel joue de manière un peu différente. Il est d'abord gouverné par le fait qu'on tend à s'exposer à des gens qui nous ressemblent. C'est une hypothèse raisonnable car elle se fonde sur un mécanisme d'homophilie que les chercheurs ont mis à jour depuis longtemps, distinguant d'ailleurs celle induite par la proximité dans le réseau (les amis de nos amis) de celle générée par similarités d'intérêt (@kossinets_origins_2009).

Sur un plan psychologique, un second mécanisme peut être ajouté, celui de l'attention sélective (@janiszewski_influence_2013) surtout si elle se conjugue à des biais de confirmation (@nickerson_confirmation_1998).

Le troisième mécanisme est technologique, c'est un mécanisme de renforcement qui se joue dans les systèmes de recommandation de nouveaux contacts et de contenus, les algorithmes amplifieraient l'exposition des sujets à ceux avec lesquels ils partagent les mêmes idées. Ce sont les chambres d'écho.

Quand l'ensemble de ces mécanismes s'associent, chacun se trouverait ainsi plus ou moins rapidement isolé dans une bulle dont la surface est le prisme de nos préférences. Un article de @geschke_triple-filter_2019 en donne une bonne idée en distinguant justement ces trois type de filtres : individuels (notamment les biais de confirmation mais aussi de recherche de diversité), sociaux (homophilie), et technologiques (moteurs de recommandation). En examinant leurs interactions par des modèles d'agents (ABM), ils montrent que la polarisation émerge quand il y a interaction entre la diffusion centrale de l'information (mass-média), partage social de cette information et activation de systèmes de recommandation. Ces derniers pouvant modérer la polarisation lorsque ce qui est recommandé va dans le sens de la diversité de l'information.

Ouvrons une rapide parenthèse, les algorithmes de recommandation servent des buts variés. En général, l'objectif est d'incité l'utilisation à consulter le plus grand nombre de pages, pour être exposé au plus grand nombre de publicités, et à plus d'occasions de consommer. Mais des designs différents peuvent être proposés pour résoudre d'autres problèmes, dans les plateformes de musique, l'ennui est un danger et très tôt on a pensé introduire des techniques de sérendipité, le moyen de produire des sauts dans les cheminements thématiques. Les algorithmes ne sont pas monolithiques, ni dans leur conception, si dans leurs objectifs.

Fermons la parenthèse et revenons à la question principale de l'attribution d'une responsabilité aux réseaux sociaux dans le phénomène de la polarisation politique, qui se manifeste tant par l'écart croissant entre les positions relatives des valeurs de droite et gauche, que par l'intensité du rejet des uns par les autres, en la justifiant par des hypothétiques bulles de filtre qui en isolant les sujets des opinions contradictoires ou simplement différentes, conduit au renforcement et à la radicalisation des opinions ainsi qu'à une surdité croissante à l'égard des arguments des autres parties.

Pour que cette théorie le deviennent vraiment, et ainsi échappe à l'appropriation de l'idéologie, il est nécessaire que les faits ne la démentent pas. Depuis quelques années, des études à grande échelle et pour une bonne part expérimentales, ont été menées et leurs résultats publiés. Ils sont extrêmement modestes sur l'effet de polarisation, tout en démontrant l'importance des effets d'exposition.

Schématisons l'idée :

```{mermaid}
flowchart LR
Algorithmes--Renforcement--> B(Exposition Sélective)
Algorithmes --recommandation--> Homophilie
Algorithmes--nudge--> C(Attention Selective) 
Homophilie --imitation-->  C(Attention Selective) 
Homophilie --> B(Exposition Sélective)
Homophilie --conformisme-->  D(Polarisation) 
 B[Exposition Sélective]  -->  C(Attention Selective) 
 C(Attention Selective)  -->  D(Polarisation) 
 B[Exposition Sélective]  --chambre d'écho-->  D(Polarisation) 

```

La première étude empirique vient de facebook @kramer_experimental_2014, elle a été fermement critiquée dans la mesure où les sujets n'ont pas été informés violant clairement un principe déontologique évident. Il s'agissait de contrôler le fil de nouvelles d'une large population en réduisant indépendamment la proportion de messages positifs et négatifs, puis en observant les conséquences sur le caractère négatif ou positif de la production textuels des sujets exposés. L'hypothèse a été validée mais avec un effet finalement très faible. Si il y a contagion, est est superficielle.

@huszar_algorithmic_2022 ont conduit quant à eux, un audit de Twitter menant une sorte d'expérience naturelle en comparant un groupe de compte auquel le réseau n'a jamais appliqué ses algorithmes (depuis 2016) et un autre groupe, expérimental, qui subit la curation automatisée de contenu. En construisant un indicateur de multiplication, ils comparent dans 7 pays les effets sur les tweets produits par les hommes politiques et selon leur affiliation. Il apparaît que l'effet d'amplification joue, mieux à droite qu'à gauche comme attendu, mais plus pour les partis centraux que pour les extrêmes, ce qui était moins attendu . Dans le même esprit @gonzalez-bailon_asymmetric_2023 montre le même phénomène en analysant les contenus vu par 208 millions de compte facebook : c'est vers l'extrême droite que la proportion de pages et de groupes "douteux" est la plus grande, et que plus forte est la ségrégation de la consommation de news.

Très récemment @guess_how_2023 , et @nyhan_like-minded_2023 ont testé spécifiquement l'effet des algorithmes de recommandation en randomisant, au cours de la campagne présidentielle américaine de 2020, l'exposition soit aux algorithmes habituels, soit un simple fil ante-chronologique. Avec ce dernier, le temps passé sur la plateforme se réduit, ainsi que les likes et commentaires (réduction de moitié) - ce qui au passage confirme l'efficacité des algorithmes pour accroître l'exposition à la publicité - alors que la diversité des contenus auxquels les comptes sont exposés s'accroît. En revanche, même après trois mois de traitement, le degré de polarisation et plus largement les attitudes ne semblent pas changer. L'exposition sélective n'est pas modifier pour changer les opinions.

Ces effets empiriques sont si modestes, qu'un nouvel argument émerge du débat. C'est celui des petits effets (@gotz_small_2022) qui s'accumulent, éventuellement se multiplient et finalement ne sont pas incompatibles avec ce qui est observé. C'est une conception qui a trouvé rapidement sa contradiction @primbs_are_2023.A propos de notre question en voici un bon [exemple](https://tecunningham.github.io/posts/2023-07-27-meta-2020-elections-experiments.html).

Finalement, les choses apparaissent plus plus complexes, à la fois par les hypothèses, mais aussi par les processus. L'attention sélective ne sélectionne pas toujours le même, elle peut favoriser le différent, ou simplement se concentrer sur les informations qu'il faut écarter (Elimination By Aspect). L'homophilie n'est peut être pas si systématique, la réalité empirique des réseaux sociaux est qu'on a jamais affaire, ou rarement à des composants isolés : la topologie générale est celle d'un macro-composant, chacun est lié à tous et à bien moins de 6 degrés de liberté. Les systèmes de recommandation ne sont pas si efficaces que ça, et dans certain cas (musique) intègrent des composants de génération de diversité. Leur design n'est pas monolithique.

Sans compter que la crédibilité de l'information qui vient des réseaux sociaux est bien plus faible que celle des autres médias, ce qu'on y cherche c'est l'étonnant, l'amusant, le sensationnel, bref le divertissement, certainement pas des arguments pour juger le monde.

<a href="https://fr.statista.com/infographie/12344/la-credibilite-des-reseaux-sociaux-est-au-plus-bas/" title="Infographie: La crédibilité des réseaux sociaux est au plus bas | Statista"><img src="https://cdn.statcdn.com/Infographic/images/normal/12344.jpeg" alt="Infographie: La crédibilité des réseaux sociaux est au plus bas | Statista" width="100%" height="auto" style="width: 100%; height: auto !important; max-width:960px;-ms-interpolation-mode: bicubic;"/>

Peut-être finalement faut-il recentrer la question. Si la vie politique se polarise, c'est sans doute moins par l'alchimie des réseaux sociaux, que par des rapports politiques beaucoup fondamentaux. La véritable question se pose en fait dans la transformation idéologique plus que dans la frénésie médiatique. Une transformation qui se dessine dans le rapport aux institutions, et à l'incapacité de leur maîtrise.

L'expérience du Covid et de la vaccination en a sans doute été un révélateur. Pour part de la population qui s'est opposée radicalement à la vaccination, le trait discriminant était la défiance à l'égard des institutions, politiques, scientifiques et sanitaires. Il va de soi que si la confiance dans les institutions s'effondre, leur discours n'est plus audible et conduit ces acteurs à la recherche de vérités alternatives. 

La question de la polarisation reste donc d'abord une question politique, elle a surement déplacé sont axe du dipôle gauche/droite, et s'articule de plus en plus entre un pôle de défiance et un contre de confiance envers les institutions qui opposent ceux qui ont un sentiment de maîtrise et de contrôle de leur vie future et de son environnement, à ceux dont "l'avenir est confisqué" pour reprendre le titre la très fraîche parution de @duvoux_avenir_2023, se qui n'empêche pas de considérer comment les acteurs politiques, extrêmes ou non, emploient les technologies de l'information et de la communication pour former leurs agenda et s'emparer de parts de voix. 
